{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a101d07-c339-4863-9102-da0f8ec6a3d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is based on the ComboLoss model by Xu and Xiang, found here: https://github.com/lucasxlu/ComboLoss\n",
    "#It was originally written to be run on Amazon sagemaker. \n",
    "#I made several modifications, including:\n",
    "#1. Changing the number of classification classes\n",
    "#2. Addingcode to allow for freezing model layers\n",
    "#3. Changing the method for loading image files\n",
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models\n",
    "from torch import nn, optim, as_tensor\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.init import *\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "import s3fs\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, accuracy_score\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "#sys.path.append('../')\n",
    "import losses #Find in ComboLoss Github https://github.com/lucasxlu/ComboLoss\n",
    "from file_util import mkdirs_if_not_exist ##Find in ComboLoss Github\n",
    "from cfg import cfg #Find in ComboLoss Github\n",
    "from losses import CombinedLoss, SmoothHuberLoss #Find in ComboLoss Github\n",
    "from nets import ComboNet #Find in ComboLoss Github\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f80b98-7bd1-4e18-96d6-ae6e51286f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_img3(root, dataframe, transform=None):\n",
    "    output = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        addr = row[0]\n",
    "        labels = torch.Tensor([row[1]])  # second column\n",
    "        class_ = torch.Tensor([row[2]]).long()  # third column\n",
    "        class_ = class_-1 #Columns ran from 1-10, needed 0-9\n",
    "\n",
    "        try:\n",
    "            with fs.open(os.path.join(root, addr)) as f:\n",
    "                img = Image.open(f).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Skipping file: {addr} (File not found)\")\n",
    "            continue\n",
    "\n",
    "        if transform is not None:\n",
    "            img = transform(img)\n",
    "\n",
    "        output.append([img, labels, class_])  # include class in the output\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8638a3c-816c-4b93-ab51-f7427eba8edf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file: g_7.jpg (File not found)\n",
      "Skipping file: model-4493512_1920.jpg (File not found)\n",
      "Skipping file: brown-4197806_1920.jpg (File not found)\n",
      "Skipping file: pexels-nishant-aneja-2561432.jpg (File not found)\n",
      "Skipping file: puvvukonvict-photography-AtpSEe3yoIg-unsplash.jpg (File not found)\n",
      "Skipping file: guy14.jpg (File not found)\n",
      "Skipping file: kamal-alkhatib-IETO_Z0BrsE-unsplash.jpg (File not found)\n",
      "Skipping file: brunette-2478405_1920.jpg (File not found)\n",
      "Skipping file: dollar-gill-nGWo2KbJERc-unsplash.jpg (File not found)\n",
      "Skipping file: model-633771_1920.jpg (File not found)\n",
      "Skipping file: guy10.jpg (File not found)\n",
      "Skipping file: abhimanyu-patel-o2g-PaaeD_U-unsplash.jpg (File not found)\n",
      "Skipping file: shifaaz-shamoon-MqLy-G-dBi8-unsplash.jpg (File not found)\n",
      "Skipping file: mateus-campos-felipe-64sktAOWasI-unsplash.jpg (File not found)\n",
      "Skipping file: kazi-mizan-PDDfWeh44m8-unsplash.jpg (File not found)\n",
      "Skipping file: rohan-g-T9ckn3XHHnA-unsplash.jpg (File not found)\n",
      "Skipping file: muhammad-murtaza-ghani-nUjfEYmJYl0-unsplash.jpg (File not found)\n",
      "Skipping file: boy-1105361_1920.jpg (File not found)\n",
      "Skipping file: pexels-hoang-gia-huy-6465256.jpg (File not found)\n",
      "Skipping file: md-duran-msnDjv5cC_U-unsplash.jpg (File not found)\n",
      "Skipping file: charlize-theron-669608_1280.jpg (File not found)\n",
      "Skipping file: payton-tuttle-n_RdRxH_7h4-unsplash.jpg (File not found)\n",
      "Skipping file: vicky-hladynets-NnmUHZ6tpSs-unsplash.jpg (File not found)\n",
      "Skipping file: male-model-1221915_1920.jpg (File not found)\n",
      "Skipping file: girl2.jpg (File not found)\n",
      "Skipping file: girl1.jpg (File not found)\n",
      "Skipping file: sung-wang-g4DgCF90EM4-unsplash.jpg (File not found)\n",
      "Skipping file: man-3733308_1920.jpg (File not found)\n",
      "Skipping file: man-5880780_1920.jpg (File not found)\n",
      "Skipping file: pexels-andrea-piacquadio-3831631.jpg (File not found)\n",
      "Skipping file: juanma-velasquez-JrNsKhB5aRQ-unsplash.jpg (File not found)\n",
      "Skipping file: creating-a-brand-WxAOdbDpMiU-unsplash.jpg (File not found)\n"
     ]
    }
   ],
   "source": [
    "#Image augmentation for the training data\n",
    "transform_train  = transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.GaussianBlur(5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                              ])\n",
    "                           \n",
    "bucket = '' #S3 bucket\n",
    "train_key = 'train_2022_mod_class.txt' #Filenames and labels\n",
    "root = '' #Folder with images\n",
    "\n",
    "\n",
    "traindir =  's3://{}/{}'.format(bucket, train_key) #Get information\n",
    "traindir2 = pd.read_table(traindir, delimiter = ' ', header = None) #Read it\n",
    "train_dataset = read_img3(root, traindir2, transform=transform_train) #Then read in images\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True) #And put in dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa19a996-00dc-4789-8f31-adc9fa329fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file: freckles-2411973_1920.jpg (File not found)\n",
      "Skipping file: muhammad-murtaza-ghani-ShxuPMbO1lM-unsplash.jpg (File not found)\n",
      "Skipping file: george-rinon-rJSfWc6qSI8-unsplash.jpg (File not found)\n",
      "Skipping file: g_9.jpg (File not found)\n",
      "Skipping file: gregory-buzdyk-bdbC8RlXSUU-unsplash.jpg (File not found)\n",
      "Skipping file: pexels-ethan-jones-3222422.jpg (File not found)\n",
      "Skipping file: business-man-1385050_1920.jpg (File not found)\n"
     ]
    }
   ],
   "source": [
    "val_transforms  = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                          ])\n",
    "\n",
    "val_key = ''\n",
    "valdir =  's3://{}/{}'.format(bucket, val_key)\n",
    "valdir2 = pd.read_table(valdir, delimiter = ' ', header = None)\n",
    "val_dataset = read_img3(root, valdir2, transform=val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122a97ab-33ec-4029-aac4-c1bec2c61950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file: children-82272_1920.jpg (File not found)\n",
      "Skipping file: man-1488305_1920.jpg (File not found)\n",
      "Skipping file: 116.jpg (File not found)\n",
      "Skipping file: young-1761404_1920.jpg (File not found)\n",
      "Skipping file: montgomery-clift-402456_1920.jpg (File not found)\n",
      "Skipping file: esther-williams-402543_1920.jpg (File not found)\n",
      "Skipping file: islander-images-kwHBTNUQIqs-unsplash.jpg (File not found)\n",
      "Skipping file: ashkan-forouzani-YlAp3Y7VUmA-unsplash.jpg (File not found)\n",
      "Skipping file: pexels-anna-tarazevich-5119607.jpg (File not found)\n",
      "Skipping file: pexels-nh-noyon-4250862.jpg (File not found)\n"
     ]
    }
   ],
   "source": [
    "test_transforms  = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                          ])\n",
    "\n",
    "test_key = 'test_2022_mod_class.txt'\n",
    "testdir =  's3://{}/{}'.format(bucket, test_key)\n",
    "testdir2 = pd.read_table(testdir, delimiter = ' ', header = None)\n",
    "test_dataset = read_img3(root, testdir2, transform=val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344f067b-e3cb-43d5-ac8b-f48c2548e4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training function\n",
    "\n",
    "def train_combinator(model, dataloaders, criterion, optimizer, scheduler, num_epochs, inference=False):\n",
    "    \"\"\"\n",
    "    train combinator\n",
    "    :param model:\n",
    "    :param dataloaders:\n",
    "    :param criterion:\n",
    "    :param optimizer:\n",
    "    :param scheduler:\n",
    "    :param num_epochs:\n",
    "    :param inference:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(model)\n",
    "    model_name = model.__class__.__name__\n",
    "    model = model.float()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() and cfg['use_gpu'] else 'cpu')\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    dataset_sizes = {x: dataloaders[x].__len__() for x in ['train', 'val', 'test']}\n",
    "\n",
    "    if not inference:\n",
    "        print('Start training %s...' % model_name)\n",
    "        since = time.time()\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_record = {\n",
    "            'pc': 0.0,\n",
    "            'epoch': 0\n",
    "        }\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('-' * 100)\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    if torch.__version__ <= '1.1.0':\n",
    "                        scheduler.step()\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                epoch_gt = []\n",
    "                epoch_pred = []\n",
    "\n",
    "                # Iterate over data.\n",
    "                # for data in dataloaders[phase]:\n",
    "                for i, data in enumerate(dataloaders[phase], 0):\n",
    "\n",
    "                    inputs = data[0].to(device)\n",
    "                    scores = data[1].squeeze(1).to(device).float()\n",
    "                    classes = data[2].squeeze(1).to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        regression_output, classification_output = model(inputs)\n",
    "                        regression_output = regression_output.view(-1)\n",
    "                        _, predicted = torch.max(classification_output.data, 1)\n",
    "\n",
    "                        loss = criterion(regression_output, scores, F.softmax(classification_output, 1), predicted,\n",
    "                                         classes)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_gt += scores.to('cpu').detach().numpy().ravel().tolist()\n",
    "                    epoch_pred += regression_output.to('cpu').detach().numpy().ravel().tolist()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    if torch.__version__ >= '1.1.0':\n",
    "                        scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "                epoch_mae = round(mean_absolute_error(np.array(epoch_gt).flatten(), np.array(epoch_pred).flatten()), 4)\n",
    "                epoch_rmse = round(\n",
    "                    np.math.sqrt(mean_squared_error(np.array(epoch_gt).flatten(), np.array(epoch_pred).flatten())), 4)\n",
    "                epoch_pc = round(np.corrcoef(np.array(epoch_gt).flatten(), np.array(epoch_pred).flatten())[0, 1], 4)\n",
    "\n",
    "                print('[{}] Loss: {:.4f} MAE: {} RMSE: {} PC: {}'\n",
    "                      .format(phase, epoch_loss, epoch_mae, epoch_rmse, epoch_pc))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_pc > best_record['pc']:\n",
    "                    best_record['pc'] = epoch_pc\n",
    "                    best_record['epoch'] = epoch\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    mkdirs_if_not_exist('./model')\n",
    "                    torch.save(model.state_dict(),\n",
    "                               './model/{0}_best_epoch-{1}.pth'.format(model_name, epoch))\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('+' * 100)\n",
    "        print('Epoch {} achieves best PC: {:4f}'.format(best_record['epoch'], best_record['pc']))\n",
    "        print('+' * 100)\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        mkdirs_if_not_exist('./model')\n",
    "        torch.save(model.state_dict(), './model/%s.pth' % model_name)\n",
    "    else:\n",
    "        print('Start testing %s...' % model_name)\n",
    "        model.load_state_dict(torch.load(os.path.join('./model/%s.pth' % model_name)))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images = data['image']\n",
    "            images = images.to(device)\n",
    "\n",
    "            filenames += data['filename']\n",
    "            regression_output, classification_output = model(images)\n",
    "            probs = F.softmax(classification_output, dim=1)\n",
    "            cls = torch.from_numpy(np.array([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]], dtype=np.float).T).to(device)  # for SCUT-FBP*\n",
    "            # cls = torch.from_numpy(np.array([[1.0, 2.0, 3.0]], dtype=np.float).T).to(device)  # for HotOrNot\n",
    "            # expectation = torch.matmul(probs, cls.float()).view(-1).view(-1, 1)\n",
    "\n",
    "            # output = (2 * regression_output + expectation) / 3\n",
    "            output = regression_output\n",
    "            total += images.size(0)\n",
    "\n",
    "            y_pred += output.to(\"cpu\").detach().numpy().tolist()\n",
    "            y_true += data['score'].detach().numpy().tolist()\n",
    "\n",
    "    mae = round(mean_absolute_error(np.array(y_true).ravel(), np.array(y_pred).ravel()), 4)\n",
    "    rmse = round(np.math.sqrt(mean_squared_error(np.array(y_true).ravel(), np.array(y_pred).ravel())), 4)\n",
    "    pc = round(np.corrcoef(np.array(y_true).ravel(), np.array(y_pred).ravel())[0, 1], 4)\n",
    "\n",
    "    print('===============The Mean Absolute Error of {0} is {1}===================='.format(model_name, mae))\n",
    "    print('===============The Root Mean Square Error of {0} is {1}===================='.format(model_name, rmse))\n",
    "    print('===============The Pearson Correlation of {0} is {1}===================='.format(model_name, pc))\n",
    "\n",
    "    col = ['filename', 'gt', 'pred']\n",
    "    df = pd.DataFrame([[filenames[i], y_true[i], y_pred[i][0]] for i in range(len(y_true))],\n",
    "                      columns=col)\n",
    "    df.to_excel(\"./{0}.xlsx\".format(model_name), sheet_name='Output', index=False)\n",
    "    print('Output Excel has been generated~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad14fed-eaec-465c-81fc-09357f738d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(model, model_type):\n",
    "    \"\"\"\n",
    "    train model\n",
    "    :param model:\n",
    "    :param data_name: SCUT-FBP/HotOrNot/SCUT-FBP5500\n",
    "    :param model_type: classifier/regressor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    xent_weight_list = None\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader, 'test':test_loader}\n",
    "    xent_weight_list = [170.7, 73.1, 10.0, 3.2, 1.6, 1.1, 1.0, 2.2, 19.0, 512.0] #This refers to the relative frequency of each class in the training data\n",
    "        \n",
    "    if model_type == 'regressor':\n",
    "        # criterion = nn.MSELoss()\n",
    "        # criterion = nn.SmoothL1Loss()\n",
    "        # criterion = nn.L1Loss()\n",
    "        criterion = SmoothHuberLoss() #Custom regression + classification loss function\n",
    "\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "        train_regressor(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n",
    "                        scheduler=exp_lr_scheduler, num_epochs=cfg['epoch'], inference=False)\n",
    "    elif model_type == 'classifier':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "        train_classifier(model, criterion, optimizer, scheduler=exp_lr_scheduler, dataloaders=dataloaders,\n",
    "                         num_epochs=cfg['epoch'], inference=False)\n",
    "    elif model_type == 'combinator':\n",
    "        criterion = CombinedLoss(xent_weight=xent_weight_list)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01,  momentum=0.9, weight_decay=0.001)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "        train_combinator(model, dataloaders, criterion, optimizer, scheduler=exp_lr_scheduler, num_epochs=cfg['epoch'],\n",
    "                         inference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0b6d4f2-de38-41e3-a343-cbc7a8b9520d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ComboNet...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0/499\n",
      "[train] Loss: 98.4180 MAE: 1.4467 RMSE: 1.932 PC: 0.1674\n",
      "[val] Loss: 83.0404 MAE: 1.0161 RMSE: 1.2439 PC: 0.5164\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/499\n",
      "[train] Loss: 82.5994 MAE: 1.0201 RMSE: 1.2713 PC: 0.4257\n",
      "[val] Loss: 92.3691 MAE: 1.1804 RMSE: 1.4424 PC: 0.521\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2/499\n",
      "[train] Loss: 76.2130 MAE: 0.8678 RMSE: 1.107 PC: 0.5595\n",
      "[val] Loss: 76.5167 MAE: 0.8716 RMSE: 1.1101 PC: 0.5696\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3/499\n",
      "[train] Loss: 72.0632 MAE: 0.7834 RMSE: 1.0021 PC: 0.655\n",
      "[val] Loss: 75.9597 MAE: 0.8723 RMSE: 1.1303 PC: 0.6315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4/499\n",
      "[train] Loss: 70.6167 MAE: 0.7642 RMSE: 0.9778 PC: 0.6767\n",
      "[val] Loss: 75.7100 MAE: 0.8869 RMSE: 1.1169 PC: 0.6632\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5/499\n",
      "[train] Loss: 68.3059 MAE: 0.7345 RMSE: 0.9363 PC: 0.7123\n",
      "[val] Loss: 77.5886 MAE: 0.8947 RMSE: 1.1959 PC: 0.6227\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 6/499\n",
      "[train] Loss: 67.0143 MAE: 0.7044 RMSE: 0.9055 PC: 0.7325\n",
      "[val] Loss: 78.0399 MAE: 0.8843 RMSE: 1.1509 PC: 0.5468\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 7/499\n",
      "[train] Loss: 64.5563 MAE: 0.6526 RMSE: 0.8485 PC: 0.7673\n",
      "[val] Loss: 80.3447 MAE: 0.992 RMSE: 1.2968 PC: 0.6493\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 8/499\n",
      "[train] Loss: 63.3798 MAE: 0.6271 RMSE: 0.8108 PC: 0.7922\n",
      "[val] Loss: 84.6149 MAE: 1.0517 RMSE: 1.2959 PC: 0.5496\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 9/499\n",
      "[train] Loss: 60.5628 MAE: 0.5751 RMSE: 0.7565 PC: 0.821\n",
      "[val] Loss: 74.1928 MAE: 0.8339 RMSE: 1.0602 PC: 0.6279\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 10/499\n",
      "[train] Loss: 59.0988 MAE: 0.5528 RMSE: 0.7088 PC: 0.844\n",
      "[val] Loss: 73.5568 MAE: 0.8033 RMSE: 1.0535 PC: 0.6231\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 11/499\n",
      "[train] Loss: 58.1457 MAE: 0.5356 RMSE: 0.6924 PC: 0.8524\n",
      "[val] Loss: 74.6944 MAE: 0.8556 RMSE: 1.1297 PC: 0.6399\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 12/499\n",
      "[train] Loss: 56.5936 MAE: 0.5009 RMSE: 0.6511 PC: 0.8701\n",
      "[val] Loss: 71.9429 MAE: 0.8023 RMSE: 1.0823 PC: 0.6725\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 13/499\n",
      "[train] Loss: 55.6095 MAE: 0.4945 RMSE: 0.6391 PC: 0.8764\n",
      "[val] Loss: 75.2792 MAE: 0.8685 RMSE: 1.179 PC: 0.6554\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 14/499\n",
      "[train] Loss: 54.0027 MAE: 0.4635 RMSE: 0.5988 PC: 0.8918\n",
      "[val] Loss: 70.8082 MAE: 0.7573 RMSE: 1.0263 PC: 0.6802\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 15/499\n",
      "[train] Loss: 53.6563 MAE: 0.4632 RMSE: 0.5893 PC: 0.8955\n",
      "[val] Loss: 73.6689 MAE: 0.8265 RMSE: 1.0523 PC: 0.6369\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 16/499\n",
      "[train] Loss: 52.2979 MAE: 0.4375 RMSE: 0.5592 PC: 0.906\n",
      "[val] Loss: 73.5093 MAE: 0.8254 RMSE: 1.0684 PC: 0.6766\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 17/499\n",
      "[train] Loss: 52.0984 MAE: 0.4468 RMSE: 0.5738 PC: 0.9017\n",
      "[val] Loss: 74.6712 MAE: 0.8366 RMSE: 1.0516 PC: 0.6563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 18/499\n",
      "[train] Loss: 51.4447 MAE: 0.4296 RMSE: 0.5513 PC: 0.9094\n",
      "[val] Loss: 71.8568 MAE: 0.7966 RMSE: 1.0889 PC: 0.6878\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 19/499\n",
      "[train] Loss: 49.0280 MAE: 0.3914 RMSE: 0.5022 PC: 0.9252\n",
      "[val] Loss: 72.5999 MAE: 0.7912 RMSE: 1.0086 PC: 0.6626\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 20/499\n",
      "[train] Loss: 48.4669 MAE: 0.3753 RMSE: 0.4857 PC: 0.9298\n",
      "[val] Loss: 72.8825 MAE: 0.8101 RMSE: 1.0569 PC: 0.6366\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 21/499\n",
      "[train] Loss: 49.9449 MAE: 0.4157 RMSE: 0.536 PC: 0.9151\n",
      "[val] Loss: 72.0145 MAE: 0.7783 RMSE: 1.0068 PC: 0.6761\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 22/499\n",
      "[train] Loss: 48.9469 MAE: 0.3999 RMSE: 0.5132 PC: 0.9225\n",
      "[val] Loss: 72.6475 MAE: 0.7996 RMSE: 1.0765 PC: 0.65\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 23/499\n",
      "[train] Loss: 48.2031 MAE: 0.3912 RMSE: 0.5027 PC: 0.925\n",
      "[val] Loss: 77.3346 MAE: 0.9119 RMSE: 1.1397 PC: 0.628\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 24/499\n",
      "[train] Loss: 45.7245 MAE: 0.3333 RMSE: 0.4264 PC: 0.9467\n",
      "[val] Loss: 74.5680 MAE: 0.8263 RMSE: 1.0385 PC: 0.6745\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 25/499\n",
      "[train] Loss: 45.3079 MAE: 0.3261 RMSE: 0.4191 PC: 0.9482\n",
      "[val] Loss: 71.5049 MAE: 0.7694 RMSE: 0.998 PC: 0.6718\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 26/499\n",
      "[train] Loss: 45.3389 MAE: 0.3318 RMSE: 0.4293 PC: 0.9459\n",
      "[val] Loss: 72.1786 MAE: 0.7809 RMSE: 1.0008 PC: 0.6745\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 27/499\n",
      "[train] Loss: 45.1528 MAE: 0.339 RMSE: 0.4331 PC: 0.9449\n",
      "[val] Loss: 72.6630 MAE: 0.7967 RMSE: 1.0102 PC: 0.6729\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 28/499\n",
      "[train] Loss: 44.2931 MAE: 0.3133 RMSE: 0.4061 PC: 0.9515\n",
      "[val] Loss: 76.0077 MAE: 0.8843 RMSE: 1.1595 PC: 0.6624\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 29/499\n",
      "[train] Loss: 43.4016 MAE: 0.305 RMSE: 0.391 PC: 0.9552\n",
      "[val] Loss: 73.3685 MAE: 0.8341 RMSE: 1.0379 PC: 0.681\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 30/499\n",
      "[train] Loss: 42.8612 MAE: 0.2974 RMSE: 0.385 PC: 0.9566\n",
      "[val] Loss: 71.9212 MAE: 0.7907 RMSE: 1.0348 PC: 0.6721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 31/499\n",
      "[train] Loss: 43.4295 MAE: 0.3111 RMSE: 0.3979 PC: 0.9535\n",
      "[val] Loss: 71.6864 MAE: 0.7653 RMSE: 1.0145 PC: 0.6763\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 32/499\n",
      "[train] Loss: 42.5858 MAE: 0.3005 RMSE: 0.3878 PC: 0.9558\n",
      "[val] Loss: 72.4118 MAE: 0.7786 RMSE: 1.0128 PC: 0.6586\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 33/499\n",
      "[train] Loss: 41.2389 MAE: 0.2724 RMSE: 0.351 PC: 0.964\n",
      "[val] Loss: 72.9373 MAE: 0.7986 RMSE: 1.0269 PC: 0.6568\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 34/499\n",
      "[train] Loss: 41.1489 MAE: 0.2687 RMSE: 0.3394 PC: 0.9664\n",
      "[val] Loss: 73.9316 MAE: 0.8136 RMSE: 1.0446 PC: 0.672\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 35/499\n",
      "[train] Loss: 40.7942 MAE: 0.2666 RMSE: 0.3435 PC: 0.9656\n",
      "[val] Loss: 71.5763 MAE: 0.7718 RMSE: 1.006 PC: 0.6665\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 36/499\n",
      "[train] Loss: 41.1369 MAE: 0.274 RMSE: 0.3527 PC: 0.9637\n",
      "[val] Loss: 71.9307 MAE: 0.7787 RMSE: 1.0445 PC: 0.6582\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 37/499\n",
      "[train] Loss: 41.1084 MAE: 0.2712 RMSE: 0.356 PC: 0.9629\n",
      "[val] Loss: 73.2596 MAE: 0.8095 RMSE: 1.0904 PC: 0.6712\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 38/499\n",
      "[train] Loss: 41.0718 MAE: 0.2764 RMSE: 0.3625 PC: 0.9618\n",
      "[val] Loss: 70.5956 MAE: 0.7509 RMSE: 1.0019 PC: 0.697\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 39/499\n",
      "[train] Loss: 41.3378 MAE: 0.2782 RMSE: 0.3649 PC: 0.961\n",
      "[val] Loss: 72.8053 MAE: 0.7803 RMSE: 1.0131 PC: 0.6592\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 40/499\n",
      "[train] Loss: 40.1864 MAE: 0.2539 RMSE: 0.3374 PC: 0.9668\n",
      "[val] Loss: 71.5463 MAE: 0.7792 RMSE: 1.0124 PC: 0.6802\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 41/499\n",
      "[train] Loss: 39.7687 MAE: 0.2495 RMSE: 0.3282 PC: 0.9687\n",
      "[val] Loss: 72.4709 MAE: 0.788 RMSE: 1.0278 PC: 0.6526\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 42/499\n",
      "[train] Loss: 39.8797 MAE: 0.2516 RMSE: 0.3257 PC: 0.9691\n",
      "[val] Loss: 72.2840 MAE: 0.785 RMSE: 1.0468 PC: 0.6829\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 43/499\n",
      "[train] Loss: 39.0075 MAE: 0.2418 RMSE: 0.3156 PC: 0.9711\n",
      "[val] Loss: 75.9309 MAE: 0.8484 RMSE: 1.0778 PC: 0.6431\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 44/499\n",
      "[train] Loss: 39.5692 MAE: 0.2491 RMSE: 0.3236 PC: 0.9695\n",
      "[val] Loss: 74.3604 MAE: 0.8232 RMSE: 1.1007 PC: 0.6474\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 45/499\n",
      "[train] Loss: 39.3254 MAE: 0.2447 RMSE: 0.3237 PC: 0.9695\n",
      "[val] Loss: 73.1279 MAE: 0.7928 RMSE: 1.0403 PC: 0.6388\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 46/499\n",
      "[train] Loss: 39.1912 MAE: 0.2428 RMSE: 0.3108 PC: 0.9719\n",
      "[val] Loss: 71.5471 MAE: 0.7695 RMSE: 1.0108 PC: 0.6642\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 47/499\n",
      "[train] Loss: 38.9518 MAE: 0.2346 RMSE: 0.3117 PC: 0.9717\n",
      "[val] Loss: 72.9817 MAE: 0.7977 RMSE: 1.0684 PC: 0.6617\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 48/499\n",
      "[train] Loss: 38.0190 MAE: 0.2149 RMSE: 0.2818 PC: 0.9769\n",
      "[val] Loss: 72.2465 MAE: 0.773 RMSE: 1.0231 PC: 0.6626\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 49/499\n",
      "[train] Loss: 38.2383 MAE: 0.222 RMSE: 0.2906 PC: 0.9754\n",
      "[val] Loss: 71.5957 MAE: 0.7751 RMSE: 1.0121 PC: 0.6615\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 50/499\n",
      "[train] Loss: 36.5448 MAE: 0.1776 RMSE: 0.2338 PC: 0.9842\n",
      "[val] Loss: 70.5886 MAE: 0.756 RMSE: 0.998 PC: 0.6739\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 51/499\n",
      "[train] Loss: 35.0438 MAE: 0.1445 RMSE: 0.1906 PC: 0.9895\n",
      "[val] Loss: 70.7973 MAE: 0.7591 RMSE: 1.0012 PC: 0.6704\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 52/499\n",
      "[train] Loss: 34.1875 MAE: 0.1231 RMSE: 0.1634 PC: 0.9923\n",
      "[val] Loss: 71.0200 MAE: 0.7627 RMSE: 1.0105 PC: 0.6707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 53/499\n",
      "[train] Loss: 33.4072 MAE: 0.1101 RMSE: 0.1481 PC: 0.9937\n",
      "[val] Loss: 71.4155 MAE: 0.7644 RMSE: 1.013 PC: 0.6716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 54/499\n",
      "[train] Loss: 33.1806 MAE: 0.101 RMSE: 0.1389 PC: 0.9945\n",
      "[val] Loss: 70.8104 MAE: 0.7565 RMSE: 1.005 PC: 0.6733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 55/499\n",
      "[train] Loss: 32.7767 MAE: 0.0889 RMSE: 0.1211 PC: 0.9958\n",
      "[val] Loss: 70.8034 MAE: 0.7573 RMSE: 1.0024 PC: 0.6748\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 56/499\n",
      "[train] Loss: 32.6393 MAE: 0.0838 RMSE: 0.1147 PC: 0.9962\n",
      "[val] Loss: 70.7984 MAE: 0.7567 RMSE: 1.0036 PC: 0.6746\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 57/499\n",
      "[train] Loss: 32.4789 MAE: 0.0821 RMSE: 0.1116 PC: 0.9964\n",
      "[val] Loss: 70.4043 MAE: 0.7503 RMSE: 0.9926 PC: 0.6777\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 58/499\n",
      "[train] Loss: 32.4372 MAE: 0.0773 RMSE: 0.1066 PC: 0.9967\n",
      "[val] Loss: 70.7440 MAE: 0.7544 RMSE: 0.9985 PC: 0.6725\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 59/499\n",
      "[train] Loss: 32.4243 MAE: 0.0749 RMSE: 0.1004 PC: 0.9971\n",
      "[val] Loss: 70.6710 MAE: 0.7533 RMSE: 1.0017 PC: 0.6751\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 60/499\n",
      "[train] Loss: 31.8167 MAE: 0.0661 RMSE: 0.0904 PC: 0.9977\n",
      "[val] Loss: 70.7140 MAE: 0.7531 RMSE: 0.9976 PC: 0.6761\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 61/499\n",
      "[train] Loss: 32.1402 MAE: 0.0677 RMSE: 0.0909 PC: 0.9976\n",
      "[val] Loss: 70.5471 MAE: 0.7502 RMSE: 0.9947 PC: 0.6776\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 62/499\n",
      "[train] Loss: 31.9844 MAE: 0.063 RMSE: 0.0875 PC: 0.9978\n",
      "[val] Loss: 70.4742 MAE: 0.749 RMSE: 0.9889 PC: 0.6798\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 63/499\n",
      "[train] Loss: 31.6962 MAE: 0.0658 RMSE: 0.0888 PC: 0.9977\n",
      "[val] Loss: 70.9427 MAE: 0.7543 RMSE: 0.9981 PC: 0.6773\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 64/499\n",
      "[train] Loss: 31.7021 MAE: 0.0603 RMSE: 0.0806 PC: 0.9981\n",
      "[val] Loss: 70.4056 MAE: 0.7479 RMSE: 0.9902 PC: 0.6816\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 65/499\n",
      "[train] Loss: 31.7711 MAE: 0.063 RMSE: 0.0853 PC: 0.9979\n",
      "[val] Loss: 70.6541 MAE: 0.7525 RMSE: 0.9999 PC: 0.6799\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 66/499\n",
      "[train] Loss: 31.8065 MAE: 0.0582 RMSE: 0.0782 PC: 0.9982\n",
      "[val] Loss: 70.3247 MAE: 0.7463 RMSE: 0.997 PC: 0.6808\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 67/499\n",
      "[train] Loss: 31.4185 MAE: 0.0551 RMSE: 0.0747 PC: 0.9984\n",
      "[val] Loss: 70.4756 MAE: 0.7484 RMSE: 0.9931 PC: 0.6807\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 68/499\n",
      "[train] Loss: 31.5372 MAE: 0.0569 RMSE: 0.0764 PC: 0.9983\n",
      "[val] Loss: 70.8291 MAE: 0.7548 RMSE: 1.0017 PC: 0.6783\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 69/499\n",
      "[train] Loss: 31.7133 MAE: 0.0598 RMSE: 0.0841 PC: 0.998\n",
      "[val] Loss: 70.3943 MAE: 0.7456 RMSE: 0.9884 PC: 0.6799\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 70/499\n",
      "[train] Loss: 31.5750 MAE: 0.0567 RMSE: 0.0746 PC: 0.9984\n",
      "[val] Loss: 70.5022 MAE: 0.749 RMSE: 0.99 PC: 0.6795\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 71/499\n",
      "[train] Loss: 31.5073 MAE: 0.0567 RMSE: 0.0787 PC: 0.9982\n",
      "[val] Loss: 70.8820 MAE: 0.7536 RMSE: 1.0002 PC: 0.6775\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 72/499\n",
      "[train] Loss: 31.2527 MAE: 0.0575 RMSE: 0.0765 PC: 0.9983\n",
      "[val] Loss: 70.7571 MAE: 0.752 RMSE: 1.0053 PC: 0.6756\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 73/499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-eef575e18333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# resnet18.fc = nn.Linear(num_ftrs, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComboNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'combinator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# main(seresnext50, 'SCUT-FBP5500', 'regressor')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cd846f56d52e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, model_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         train_combinator(model, dataloaders, criterion, optimizer, scheduler=exp_lr_scheduler, num_epochs=cfg['epoch'],\n\u001b[0;32m---> 34\u001b[0;31m                          inference=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c66c19a5eeaf>\u001b[0m in \u001b[0;36mtrain_combinator\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, inference)\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                         \u001b[0mregression_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                         \u001b[0mregression_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone_net_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SEResNeXt50'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone_net_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ResNet18'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorchcv/models/seresnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorchcv/models/resnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorchcv/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seresnext50 = ptcv_get_model(\"seresnext50_32x4d\", pretrained=True)\n",
    "    num_ftrs = seresnext50.output.in_features\n",
    "    seresnext50.output = nn.Linear(num_ftrs, 1)\n",
    "    #Possibility to freeze percentages of layers\n",
    "    # Calculate the number of layers to freeze\n",
    "    #num_layers = len(list(seresnext50.features.children()))\n",
    "    #num_layers_to_freeze = num_layers // 4\n",
    "\n",
    "    # Get the layers\n",
    "    #layers = list(seresnext50.features.children())\n",
    "\n",
    "    # Freeze the first 50% of layers\n",
    "    #for i in range(num_layers_to_freeze):\n",
    "     #   for param in layers[i].parameters():\n",
    "      #      param.requires_grad = False\n",
    "\n",
    "    # Ensure remaining layers are trainable\n",
    "    #for i in range(num_layers_to_freeze, num_layers):\n",
    "     #   for param in layers[i].parameters():\n",
    "      #      param.requires_grad = True\n",
    "\n",
    "\n",
    "    # resnet18 = models.resnet18(pretrained=True)\n",
    "    # num_ftrs = resnet18.fc.in_features\n",
    "    # resnet18.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    main(ComboNet(num_out=10), 'combinator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d098a5e-2e45-4954-9824-aac37a0984d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
