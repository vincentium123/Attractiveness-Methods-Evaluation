# Attractiveness-Methods-Evaluation
This is a repository for my Master's Thesis. In it, I evaluated whether deep learning methods are sufficiently accurate at predicting human attractiveness to be used in scientific research. 
My motivation for this was two-fold: firstly, researchers have already begun using these methods without checking their accuracy. Secondly, there are several studies I'm interesting in conducting that could be done more easily with deep learning. To do this research, I had to use a variety of skills: data cleaning and modeling in R, image processing and neural network training in Python, and using Amazon products like S3 and Sagemaker. 

To test these methods, I conducted three studies. In the first, I evaluated 8 publically available deep learning methods by attempting to replicate several published studies using them. This largely failed. The data from the neural networks was too dissimilar from data from human raters to be replicate the studies. I theorized that this might be due to the training datasets being too formalized, while the images used in the studies are "from the wild" and have more variation. I attempted to fix these errors by training my own neural networks on a more naturalistic dataset. This was partially successful, with 40% of the studies replicating. Finally, in a third study, I attempted my own study on a new dataset. One of the strange findings of attractiveness research is that right-wing politicians are consistently rated as more attractive than left-wing ones. This effect has been found in a half-dozen countries since the 1980s. I ran inference on roughly 1000 photographs of members of the US Congress and found this effect as well, albeit with a smaller effect size than in most other studies. 

I have included much of the code I used in this project in this repository. Unfortunately, some I had to leave the data behind them out for privacy reasons- I received my datasets from researchers who asked me not to share them publically. 
